{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df = pd.read_excel('Data.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### Vectorising Questions "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import string #allows for format()\n",
    "import pandas\n",
    "\n",
    "mydoclist = list(df.Questions)\n",
    "\n",
    "from collections import Counter\n",
    "for doc in mydoclist:\n",
    "    tf = Counter()\n",
    "    for word in doc.split():\n",
    "        tf[word] +=1\n",
    "    #print (tf.items())    \n",
    "def build_lexicon(corpus):\n",
    "    lexicon = set()\n",
    "    for doc in corpus:\n",
    "        lexicon.update([word for word in doc.split()])\n",
    "    return lexicon\n",
    "\n",
    "def tf(term, document):\n",
    "    return freq(term, document)\n",
    "\n",
    "def freq(term, document):\n",
    "    return document.split().count(term)\n",
    "\n",
    "vocabulary = build_lexicon(mydoclist)\n",
    "\n",
    "doc_term_matrix = []\n",
    "#print ('Our vocabulary vector is [' + ', '.join(list(vocabulary)) + ']')\n",
    "for doc in mydoclist:\n",
    "    #print ('The doc is \"' + doc + '\"')\n",
    "    tf_vector = [tf(word, doc) for word in vocabulary]\n",
    "    tf_vector_string = ', '.join(format(freq, 'd') for freq in tf_vector)\n",
    "    #print ('The tf vector for Document %d is [%s]' % ((mydoclist.index(doc)+1), tf_vector_string))\n",
    "    doc_term_matrix.append(tf_vector)\n",
    "\n",
    "    # here's a test: why did I wrap mydoclist.index(doc)+1 in parens?  it returns an int...\n",
    "    # try it!  type(mydoclist.index(doc) + 1)\n",
    "\n",
    "#print ('All combined, here is our master document term matrix: ')\n",
    "#print (doc_term_matrix)\n",
    "\n",
    "for doc in mydoclist:\n",
    "    tf_vector = [tf(word, doc) for word in vocabulary]\n",
    "    #print(tf_vector)\n",
    "\n",
    "t=pandas.DataFrame(columns=[i for i in range(0,1348) ])\n",
    "cntr = 0\n",
    "for doc in mydoclist:\n",
    "    #print ('The doc is \"' + doc + '\"')\n",
    "    tf_vector = [tf(word, doc) for word in vocabulary]\n",
    "    tf_vector_string = ', '.join(format(freq, 'd') for freq in tf_vector)\n",
    "    #print (tf_vector_string)\n",
    "    c=[i for i in range(1348)]\n",
    "    #print(tf_vector)\n",
    "    if cntr == 0:\n",
    "        test = pandas.DataFrame([tf_vector])\n",
    "        #print(cntr)\n",
    "        #print(test)\n",
    "    else:\n",
    "        test = test.append([tf_vector])\n",
    "#         print(cntr)\n",
    "#         print(test)\n",
    "    cntr += 1\n",
    "    #print(cntr)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### Vectorising Key Words in Question"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import string #allows for format()\n",
    "import pandas\n",
    "\n",
    "mydoclist = list(df.Nouns)\n",
    "\n",
    "from collections import Counter\n",
    "for doc in mydoclist:\n",
    "    tf = Counter()\n",
    "    for word in doc.split():\n",
    "        tf[word] +=1\n",
    "    #print (tf.items())    \n",
    "def build_lexicon(corpus):\n",
    "    lexicon = set()\n",
    "    for doc in corpus:\n",
    "        lexicon.update([word for word in doc.split()])\n",
    "    return lexicon\n",
    "\n",
    "def tf(term, document):\n",
    "    return freq(term, document)\n",
    "\n",
    "def freq(term, document):\n",
    "    return document.split().count(term)\n",
    "\n",
    "vocabulary2= build_lexicon(mydoclist)\n",
    "\n",
    "doc_term_matrix = []\n",
    "#print ('Our vocabulary vector is [' + ', '.join(list(vocabulary)) + ']')\n",
    "for doc in mydoclist:\n",
    "    #print ('The doc is \"' + doc + '\"')\n",
    "    tf_vector = [tf(word, doc) for word in vocabulary2]\n",
    "    tf_vector_string = ', '.join(format(freq, 'd') for freq in tf_vector)\n",
    "    #print ('The tf vector for Document %d is [%s]' % ((mydoclist.index(doc)+1), tf_vector_string))\n",
    "    doc_term_matrix.append(tf_vector)\n",
    "\n",
    "    # here's a test: why did I wrap mydoclist.index(doc)+1 in parens?  it returns an int...\n",
    "    # try it!  type(mydoclist.index(doc) + 1)\n",
    "\n",
    "#print ('All combined, here is our master document term matrix: ')\n",
    "#print (doc_term_matrix)\n",
    "\n",
    "for doc in mydoclist:\n",
    "    tf_vector = [tf(word, doc) for word in vocabulary2]\n",
    "    #print(tf_vector)\n",
    "\n",
    "t=pandas.DataFrame(columns=[i for i in range(0,1348) ])\n",
    "cntr = 0\n",
    "for doc in mydoclist:\n",
    "    #print ('The doc is \"' + doc + '\"')\n",
    "    tf_vector = [tf(word, doc) for word in vocabulary2]\n",
    "    f_vector_string = ', '.join(format(freq, 'd') for freq in tf_vector)\n",
    "    #print (tf_vector_string)\n",
    "    c=[i for i in range(1348)]\n",
    "    #print(tf_vector)\n",
    "    if cntr == 0:\n",
    "        test2= pandas.DataFrame([tf_vector])\n",
    "        #print(cntr)\n",
    "        #print(test)\n",
    "    else:\n",
    "        test2= test2.append([tf_vector])\n",
    "        #print(cntr)\n",
    "        #print(test)\n",
    "    cntr += 1\n",
    "    #print(cntr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "test2C = test2.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "test2C.columns = range(test.shape[1], test.shape[1]+ test2.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "test2.index = range(len(test2))\n",
    "test.index = range(len(test))\n",
    "test2C.index = range(len(test2C))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "test3 = pd.concat([test.reset_index(drop=True), test2C], axis=1)\n",
    "\n",
    "#test has vectorised questions in dataframe. test2 does the same for nouns. test3 dataframe concatenates test and test2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "test['Question'] = list(df.Questions)\n",
    "test['Answer'] = list(df.Answers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test2['Question'] = list(df.Questions)\n",
    "test2['Answer'] = list(df.Answers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "test3['Question'] = list(df.Questions)\n",
    "test3['Answer'] = list(df.Answers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Applying Random Forest "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "TestDF = pd.DataFrame()\n",
    "TrainDF = pd.DataFrame()\n",
    "def RFModel(df, test_size=0.1):\n",
    "    global TestDF\n",
    "    global TrainDF\n",
    "    global model\n",
    "    from sklearn.metrics import accuracy_score\n",
    "    df = df[df.Answer.isnull() == False]\n",
    "    df.index = range(len(df))\n",
    "    from sklearn.cross_validation import train_test_split\n",
    "    X = df[list(range(df.shape[1]-2))]\n",
    "    y = df['Answer']\n",
    "    y = y.astype('category')\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = test_size)\n",
    "    #Import Library\n",
    "    from sklearn.ensemble import RandomForestClassifier #use RandomForestRegressor for regression problem\n",
    "    #Assumed you have, X (predictor) and Y (target) for training data set and x_test(predictor) of test_dataset\n",
    "    # Create Random Forest object\n",
    "    model= RandomForestClassifier(max_features= 'auto' ,n_estimators= 1000)\n",
    "    # Train the model using the training sets and check score\n",
    "    #model.fit(X, y)\n",
    "    #from sklearn import tree\n",
    "    #model = tree.DecisionTreeClassifier(criterion='gini')\n",
    "    model.fit(X_train, y_train)\n",
    "    model.score(X_train, y_train)\n",
    "    #Predict Output\n",
    "    if test_size > 0.01:\n",
    "        testPredicted= model.predict(X_test)\n",
    "        test = pd.DataFrame(df.loc[list(X_test.index)])\n",
    "        TestDF = test[['Question']]\n",
    "        TestDF['Prediction'] = testPredicted\n",
    "        ps = model.predict_proba(X_test)\n",
    "        prob = []\n",
    "        for i in ps:\n",
    "            prob.append(max(i))\n",
    "        TestDF['Prediction Probability'] = prob\n",
    "        testAcc = accuracy_score(y_test, testPredicted)\n",
    "        print('Test accuracy is {}'.format(testAcc))\n",
    "    trainPredicted = model.predict(X_train)\n",
    "    train = pd.DataFrame(df.loc[list(X_train.index)])\n",
    "    TrainDF = train[['Question']]\n",
    "    TrainDF['Prediction'] = trainPredicted\n",
    "    tprob = []\n",
    "    ps = model.predict_proba(X_train)\n",
    "    for i in ps:\n",
    "        tprob.append(max(i))\n",
    "    TrainDF['Prediction Probability'] = tprob\n",
    "    trainAcc = accuracy_score(y_train, trainPredicted)\n",
    "    print('Training accuracy is {}'.format(trainAcc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy is 0.953125\n",
      "Training accuracy is 0.9894366197183099\n"
     ]
    }
   ],
   "source": [
    "RFModel(test2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "TestDF.to_excel('new.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "TrainDF.to_excel('trainRF.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training accuracy is 0.9889240506329114\n"
     ]
    }
   ],
   "source": [
    "RFModel(test2, test_size=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating rules, fallback responses etc. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "courseNames = {\n",
    "    'bdva' : ['big data & visual analytics', 'big data & analytics', 'big data and visual analytics', 'big data and analytics'  'big data analytics', 'data analytics','business analytics', 'big data', 'data science', 'analytics', 'data mining', 'data', 'visualisation','machine learning', 'artificial intelligence', 'bdap', 'bdva', 'bdvap'],\n",
    "    'dmm' : ['digital marketing & metrics', 'digital marketing and metrics', 'digital marketing', 'digital metrics', 'dmm'],\n",
    "    'rm' : ['retail management', 'retail', ' rm'],\n",
    "    'emba': ['executive master of business administration', 'executive masters of business administration', 'executive master in business administration', 'executive masters in business administration', 'executive mba', 'executive', 'emba'],\n",
    "    'gmba': ['global masters of business administration', 'global master of business administration', 'global masters in business administration', 'global master in business administration', 'global mba', 'globalmba', 'gmba'],\n",
    "    'mgb' : ['masters in global business', 'masters of global business', 'master of global business', 'masters in global business', 'master in global business', 'mgb'],\n",
    "    'mba' : ['masters of business administration',' mba'],\n",
    "    'dba' : ['doctor of business administration', 'doctorate of business administration', 'business administration doctorate', 'doctor in business administration', 'business doctorate', 'doctorate', 'doctor', 'dba'],\n",
    "    'gfmb' : ['global family managed business', 'family managed business', 'family business', 'global fmb', 'gfmb', 'fmb'],\n",
    "    'bba' : ['bachelor of business administration', 'bachelor in business administration', 'bachelors in business administration', 'bachelors of business administration', 'business management', 'bba'],\n",
    "    'bec' : ['bachelor of economics', 'bachelor in economics', 'bachelors in economics', 'bachelors of economics', 'economics', 'bachelor of eco', 'bec'],\n",
    "    'bbc' : ['bachelor of business communication', 'bachelors of business communication', 'bachelor in business communication', 'bachelors in business communication', 'business communication', 'bbc'],\n",
    "    'mgluxm': ['masters in global luxury goods and services management', 'masters in global luxury management goods and services', 'masters in global luxury management', 'masters in global luxury goods and services', 'masters in global luxury management goods', 'global luxury management', 'luxury management of goods and services', 'luxury management of goods & services' 'luxury management', 'luxury goods and services management', 'luxury goods and services', 'luxury', 'mgluxm'],\n",
    "    'fintech': ['financial technology', 'finance technology', 'professional finance course', 'finance course', 'fintech']              \n",
    "}\n",
    "\n",
    "defaultResp = {\n",
    "    'bdva' : 'You can have a word with Mr. Rakesh Shetty, M: +91- 82912 87131 | Email id rakesh.shetty@spjain.org. He handles all the application for the Big Data & Visual Analytics Course.',\n",
    "    'dmm' : 'I would like to inform you that we have our Admissions Manager Mr. Ashutosh Kulkarni, based out of Mumbai.  He handles all applications for Digital Marketing & Metrics . You can get in touch with him directly. His contact details are tel no +91 9702896668, email id ashutosh.kulkarni@spjain.org . He would be your point of contact as far as DMM @ S P Jain is concerned.',\n",
    "    'rm' : 'You can have a word with Mr. Ashutosh Kulkarni, M: +91 9702896668, email id ashutosh.kulkarni@spjain.org. He handles all applications for Retail Management.',\n",
    "    'emba': 'I would like to inform you that we have our Assistant Manager- Professional Programs for EMBA Ms. Nikita Marwaha , based out of our Mumbai Campus. Ms. Nikita handles all applications for the EMBA program. You can get in touch with her directly. Her contact details are tel no 8879866774 email id nikita.marwaha@spjain.org. She would be your point of contact as far as EMBA @ S P Jain is concerned.',\n",
    "    'gmba': 'I would like to inform you that we have our Admissions Manager Ms. Mona Dabas, based out of New Delhi. Ms. Mona handles all applications for MGB & GMBA coming from your region. You can get in touch with her directly. Her contact details are tel no +91 9818206168. Email id mona.dabas@spjain.org. She would be your point of contact as far as PG @ S P Jain is concerned',\n",
    "    'mgb' : 'I would like to inform you that we have our Admissions Manager Mr. Noel Thomas, based out of Mumbai. Mr. Noel handles all applications for MGB & GMBA coming from your region. You can get in touch with him directly. His contact details are tel no +91 9322240630, email id noel.thomas@spjain.org. He would be your point of contact as far as PG @ S P Jain is concerned.',\n",
    "    'mba' : 'I would like to inform you that we have our Admissions Manager Mr. Noel Thomas, based out of Mumbai. Mr. Noel handles all applications for MGB & GMBA coming from West India You can get in touch with him directly. His contact details are tel no +91 9322240630, email id noel.thomas@spjain.org. He would be your point of contact as far as PG @ S P Jain is concerned.',\n",
    "    'dba' : 'I would like to inform you that we have our Director- Professional PG Programs Dr. Raja Roy Choudhury, based out of Mumbai.  He handles all applications for DMM/DBA. You can get in touch with him directly. His contact details are tel no 8879489681/8655502525, email id raja.royc@spjain.org  . He would be your point of contact as far as DBA/DMM @ S P Jain is concerned.',\n",
    "    'GFMB' : 'You can have a word with Ms. Tejal Dhulla, M: 9987081818|Email id tejal.dhulla@spjain.org. She handles all the application for the GFMB. She would be your point of contact as far as GFMB @ S P Jain is concerned.',\n",
    "    'bba' : 'I would like to inform you that we have our Admissions Manager Mr. Atharv Kale, based in Mumbai.  Atharv handles all applications for BBA, BBC & BEC coming from your region. You can get in touch with him directly. His contact details are Tel no +91 9920211171, email id: atharv.kale@spjain.org. He would be your point of contact as far as BBA, BBC & BEC @ S P Jain is concerned.',\n",
    "    'bec' : 'I would like to inform you that we have our Admissions Manager Mr. Atharv Kale, based in Mumbai.  Atharv handles all applications for BBA, BBC & BEC coming from your region. You can get in touch with him directly. His contact details are Tel no +91 9920211171, email id: atharv.kale@spjain.org. He would be your point of contact as far as BBA, BBC & BEC @ S P Jain is concerned.',\n",
    "    'bbc' : 'You can have a word with Mr. Mahesh Sharma, M: +91-7875874565  | Email id mahesh.sharma@spjain.org. He handles all the application for the Bachelor Of Business Communication.',\n",
    "    'mgluxm': 'I would like to inform you that we have our Admissions Manager Ms. Neha Sikri , based out of Mumbai.  She handles all applications for MGLuxM. You can get in touch with her directly. Her contact details are tel no +91 9867633315, email id Neha.sikri@spjain.org. She would be your point of contact as far as MGLuxM @ S P Jain is concerned.',\n",
    "    'fintech': 'I would like to inform you that we have our Admissions Manager Mr.Nikhil Gore , based out of Mumbai.  He handles all applications for Fintech  . You can get in touch with him directly. His contact details are tel no +91 9445431213, email id nikhil.gore@spjain.org. He would be your point of contact as far as DMM @ S P Jain is concerned.'\n",
    "    \n",
    "}\n",
    "\n",
    "greetings = [' hi', ' hello', ' how are you', ' are you there', ' there?', ' hey', ' good morning', ' good afternoon', ' good evening', ' yo ']\n",
    "\n",
    "thanks = ['thanks', 'thank', 'thx', 'thnx', 'thnks', 'thnk', 'bye', 'okay', 'ok']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def checkQ(j):\n",
    "    if '?' in j or j[0:5].lower() =='what ' or j[0:2].lower()=='do' or j[0:3].lower()=='can' \\\n",
    "    or j[0:2].lower() == 'is' or j[0:5].lower()=='would' or j[:4].lower() == 'how ':\n",
    "        return True\n",
    "    else:\n",
    "        return False\n",
    "\n",
    "def removePunct(S):\n",
    "    from nltk.tokenize import RegexpTokenizer\n",
    "    tokenizer = RegexpTokenizer(r'\\w+')\n",
    "    return ' '.join(tokenizer.tokenize(S))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Defining the chatbot function. Integrates random forest predictions, rules, fallback answers etc. It takes user input, responds to it, and asks for further input from user. Input 'quit' to stop the function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def chatbot():\n",
    "    c = ''\n",
    "    prev = ''\n",
    "    on = False\n",
    "    while on == False:\n",
    "        new = False\n",
    "        q = input().lower()\n",
    "        if checkQ(q) == False:\n",
    "            for i in thanks:\n",
    "                if i in removePunct(q).split():\n",
    "                    new = True\n",
    "                    prev = ''\n",
    "                    print('SP Jain Assistant: ' + \"It's my pleasure to have helped you. All the best!\" + '\\n')\n",
    "                    break\n",
    "                    \n",
    "        q = removePunct(q) + prev\n",
    "        query = c + ' ' + q\n",
    "        \n",
    "\n",
    "        if new:\n",
    "            continue\n",
    "            \n",
    "        if q == 'quit':\n",
    "            on = True\n",
    "            \n",
    "        else:\n",
    "            N = [tf(word, query) for word in vocabulary2]\n",
    "            probability = max(max(model.predict_proba(N)))\n",
    "            find = False\n",
    "            fin = False\n",
    "            counter = 0\n",
    "            for course in sorted(courseNames):\n",
    "                if find:\n",
    "                    break\n",
    "                else:    \n",
    "                    for name in courseNames[course]:\n",
    "                        counter +=1\n",
    "                        if name in q:\n",
    "                            find = True\n",
    "                            new = True\n",
    "                            prev = ''\n",
    "                            query = q.replace(name, ' ' + str(course) + ' ')\n",
    "                            #Q = [tf(word, query) for word in vocabulary]\n",
    "                            N = [tf(word, query) for word in vocabulary2]\n",
    "                            prob = max(max(model.predict_proba(N)))\n",
    "                            if prob>0.35:\n",
    "                                print('SP Jain Assistant: ' + model.predict(N)[0] + '\\n')\n",
    "                            elif prob >= 0.22 and model.predict(N)[0] != defaultResp[course] + ' ':\n",
    "                                print('SP Jain Assistant: ' + model.predict(N)[0] + '\\n' + defaultResp[course] + '\\n')\n",
    "                            else:\n",
    "                                print('SP Jain Assistant: ' + defaultResp[course] + '\\n')\n",
    "                            c = ' ' + course\n",
    "                            break\n",
    "                            \n",
    "                        elif counter == 97:\n",
    "                            for course in sorted(courseNames):\n",
    "                                if fin:\n",
    "                                    break\n",
    "                                else:\n",
    "                                    for name in courseNames[course]:\n",
    "                                        if name in query:\n",
    "                                            prev = ''\n",
    "                                            fin = True\n",
    "                                            new = True\n",
    "                                            query = query.replace(name, ' ' + course + ' ')\n",
    "                                            #Q = [tf(word, query) for word in vocabulary]\n",
    "                                            N = [tf(word, query) for word in vocabulary2]\n",
    "                                            prob = max(max(model.predict_proba(N)))\n",
    "                                            if prob>0.35:\n",
    "                                                print('SP Jain Assistant: ' + model.predict(N)[0] + '\\n')\n",
    "                                            elif prob >= 0.22 and model.predict(N)[0] != defaultResp[course] + ' ':\n",
    "                                                print('SP Jain Assistant: ' + model.predict(N)[0] + '\\n' + defaultResp[course] + '\\n')\n",
    "                                            else:\n",
    "                                                print('SP Jain Assistant: ' + defaultResp[course] + '\\n')\n",
    "                                            break\n",
    "                        \n",
    "\n",
    "            if find == False and fin == False:   \n",
    "                if probability > 0.4:\n",
    "                    new = True\n",
    "                    prev = ''\n",
    "                    print('SP Jain Assistant: ' + model.predict(N)[0] + '\\n')\n",
    "\n",
    "\n",
    "                if new == False:    \n",
    "                    for word in greetings:\n",
    "                        if word in query:\n",
    "                            new = True\n",
    "                            prev = ''\n",
    "                            print('SP Jain Assistant: ' + 'Hello! How may I help you?' + '\\n')\n",
    "                            break\n",
    "\n",
    "                        elif word == greetings[-1]:\n",
    "                            new = True\n",
    "                            print('SP Jain Assistant: ' + 'May I know which program you are looking for?' + '\\n')\n",
    "                            prev = q\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "<br><br><br><br><br><br><br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I want to know the fees!\n",
      "SP Jain Assistant: May I know which program you are looking for?\n",
      "\n",
      "big data analytics\n",
      "SP Jain Assistant: The fees of the Big Data & Visual Analytics Program is INR 500,000 (Plus applicable service tax)\n",
      "\n",
      "do you provide placements?\n",
      "SP Jain Assistant: We provide complete assistance for the placements\n",
      "\n",
      "how good are the placements?\n",
      "SP Jain Assistant: We provide complete assistance for the placements\n",
      "\n",
      "details on the same please?\n",
      "SP Jain Assistant: You can have a word with Mr. Rakesh Shetty, M: +91- 82912 87131 | Email id rakesh.shetty@spjain.org. He handles all the application for the Big Data & Visual Analytics Course.\n",
      "\n",
      "thanks for the help!\n",
      "SP Jain Assistant: It's my pleasure to have helped you. All the best!\n",
      "\n",
      "quit\n"
     ]
    }
   ],
   "source": [
    "chatbot()"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
